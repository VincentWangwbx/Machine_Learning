{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier (NBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Probability Review\n",
    "### 1.1 Conditional Probability\n",
    "$$p(c|x) = \\frac{p(c,x)}{p(x)}$$\n",
    "### 1.2 Bayes' Theorem\n",
    "$$p(c|x) = \\frac{p(x|c)p(c)}{p(x)}$$\n",
    "### 1.3 Principle of Classification\n",
    "Denote $c_1$ as class 1, $c_2$ as class 2, $x$, $y$ are two independent features, if we have:\n",
    "$$\\begin{align*}\n",
    "p(c_1|x,y)&>p(c_2|x,y)\\\\\n",
    "\\frac{p(x,y|c_1)p(c_1)}{p(x,y)}&>\\frac{p(x,y|c_2)p(c_2)}{p(x,y)}\\text{,}\n",
    "\\end{align*}$$\n",
    "then we say the subject is more likely to be a member of $c_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Classification\n",
    "### 2.1 Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    postings=[['my','dog','has','flea','problems','help','please'],\\\n",
    "             ['maybe','not','take','him','to','dog','park','stupid'],\\\n",
    "             ['my','dalmation','is','so','cute','I','love','him'],\\\n",
    "             ['stop','posting','stupid','worthless','garbage'],\\\n",
    "             ['mr','licks','ate','my','steaks','how','to','stop','him'],\\\n",
    "             ['quit','buying','worthless','dog','food','stupid']]\n",
    "    labels = [0,1,0,1,0,1] #1 is insulting words, 0 is not\n",
    "    return postings, labels\n",
    "\n",
    "def create_vocab_list(dataset):\n",
    "    vocab_list = set([])\n",
    "    for record in dataset:\n",
    "        vocab_list = vocab_list|set(record)\n",
    "    return list(vocab_list)\n",
    "\n",
    "def record_to_vector(record, vocab_list):\n",
    "    vector = [0]*len(vocab_list)\n",
    "    for word in record:\n",
    "        if word in vocab_list:\n",
    "            vector[vocab_list.index(word)] = 1\n",
    "        else:\n",
    "            print('The word %s is not in the vocabulary list.'%str(word))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['maybe', 'dalmation', 'mr', 'cute', 'has', 'my', 'please', 'love', 'problems', 'help', 'steaks', 'food', 'so', 'stop', 'how', 'licks', 'take', 'is', 'posting', 'buying', 'quit', 'dog', 'stupid', 'him', 'worthless', 'flea', 'ate', 'park', 'not', 'garbage', 'I', 'to']\n",
      "[0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "postings, labels = create_dataset()\n",
    "v_list = create_vocab_list(postings)\n",
    "print(v_list)\n",
    "vector_0 = record_to_vector(postings[0], v_list)\n",
    "print(vector_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Training\n",
    "Denote $w$ as a vector of a record, then we use:\n",
    "$$p(c_i|w)=\\frac{p(w|c_i)p(c_i)}{p(w)}$$\n",
    "to calculate the probability of belonging to class $i$.  \n",
    "If all features, *i.e.* $w_0,w_1,w_2,...$ are all indepent of each other, then we have:\n",
    "$$\\begin{align*}\n",
    "p(w|c_i) &= p(w_0,w_1,w_2,\\cdots|c_i)\\\\\n",
    "&= p(w_0|c_i)p(w_1|c_i)p(w_2|c_i)\\cdots p(w_N|c_i)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Information Entropy\n",
    "## 1.1 Definition\n",
    "Entrophy is a measure of the amount of uncertainty in the dataset.\n",
    "$$H(X) = -\\sum_{x\\in X} p(x) \\log_2 p(x)$$\n",
    "\n",
    "S: The current dataset for which entropy is being calculated  \n",
    "X: The set of classes in S  \n",
    "p(x): The proportion of the number of elements in class x to the number of elements in set S  \n",
    "\n",
    "Source: [wikipedia](https://en.wikipedia.org/wiki/ID3_algorithm#\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(dataset):\n",
    "    H = 0\n",
    "    m = len(dataset)\n",
    "    label_dic = {}\n",
    "    for data in dataset:\n",
    "        label = data[-1]\n",
    "        if label not in label_dic:\n",
    "            label_dic[label] = 0\n",
    "        label_dic[label] += 1\n",
    "    for key, value in label_dic.items():\n",
    "        p = value/m\n",
    "        H -= p*log(p,2)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709505944546686\n",
      "1.3709505944546687\n"
     ]
    }
   ],
   "source": [
    "test_data = [[1,1,'yes'],[1,1,'yes'],[1,0,'no'],[0,1,'no'],[0,1,'no']]\n",
    "print(entropy(test_data))\n",
    "test_data[0][-1] = 'maybe'\n",
    "print(entropy(test_data)) #larger H means greater chaos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dataset Split\n",
    "Select records whose features value meet the requirement. The selected feature will not be included in the returned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(dataset, feature, value):\n",
    "    '''dataset[i]: [feature0, feature1, ..., label],\n",
    "    extract records with record[feature] == value'''\n",
    "    split_dataset = []\n",
    "    for record in dataset:\n",
    "        if record[feature] == value:\n",
    "            split_record = record[:feature]\n",
    "            split_record.extend(record[(feature+1):])\n",
    "            split_dataset.append(split_record)\n",
    "    return split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 'yes'], [1, 'yes'], [0, 'no']]\n",
      "[[1, 'no'], [1, 'no']]\n"
     ]
    }
   ],
   "source": [
    "test_data = [[1,1,'yes'],[1,1,'yes'],[1,0,'no'],[0,1,'no'],[0,1,'no']]\n",
    "print(split(test_data, 0,1))\n",
    "print(split(test_data, 0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Choose a Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Conditional Information Entropy and Information Gain\n",
    "The feature which leads to the greatest information gain should be selected.\n",
    "$$\\begin{align*}\n",
    "H(X|Y) &= \\sum_{y \\in Y} H(X|Y=y)\\\\\n",
    "&= -\\sum_{y \\in Y}p(y) \\sum_{X=x}p(x|y)\\log{p(x|y)}\\\\\n",
    "&= -\\sum_{y \\in Y}\\sum_{X=x}p(x,y)\\log{p(x|y)}\\\\\n",
    "G(X,Y) &= H(X) - H(X|Y)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Code Implemetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_feature(dataset):\n",
    "    num = len(dataset[0]) - 1\n",
    "    HX = entropy(dataset)\n",
    "    gain = 0\n",
    "    feature_index = 0\n",
    "    for i in range(num):\n",
    "        HXY = 0\n",
    "        vector = [record[i] for record in dataset]\n",
    "        vector_set = set(vector) #find all unique values of a feature\n",
    "        for element in vector_set:\n",
    "            subdataset = split(dataset, i, element)\n",
    "            Hy = entropy(subdataset)\n",
    "            HXY += (len(subdataset)/len(dataset))*Hy #weighed by prob of each value\n",
    "        if HX - HXY > gain:\n",
    "            feature_index = i\n",
    "            gain = HX - HXY\n",
    "    return feature_index        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = [[1,1,'yes'],[1,1,'yes'],[1,0,'no'],[0,1,'no'],[0,1,'no']]\n",
    "choose_feature(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tree Construction by Recursion \n",
    "For each value of selected feature, repeat the algorithm to determine the sub-tree. Stoping criteria would be:  \n",
    "1. All records are with the same label.\n",
    "2. Records are not with the same label while running out of features, use the most common label to mark this leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(dataset, feature_name):\n",
    "    '''Use a dict to record structure of a tree'''\n",
    "    labels = [record[-1] for record in dataset]\n",
    "    if labels.count(labels[0]) == len(labels): #all records are with the same label\n",
    "        return labels[0]\n",
    "    if len(dataset[0]) == 1:\n",
    "        return Counter(labels).most_common(1)[0][0] #if all features have been traversed, return the most popular label\n",
    "    \n",
    "    best_feature = choose_feature(dataset)\n",
    "    best_feature_name = feature_name[best_feature]\n",
    "    tree = {best_feature_name:{}}\n",
    "    feature_name = feature_name[:best_feature] + feature_name[best_feature+1:]\n",
    "    \n",
    "    vector = [record[best_feature] for record in dataset]\n",
    "    vector_set = set(vector)\n",
    "    for value in vector_set:\n",
    "        tree[best_feature_name][value] = ID3(split(dataset, best_feature,value),feature_name)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = [[1,1,'yes'],[1,1,'yes'],[1,0,'no'],[0,1,'no'],[0,1,'no']]\n",
    "ID3(test_data, ['no surfacing','flippers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot the Structure of Tree\n",
    "To be compeleted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use a Decision Tree for Classification\n",
    "Assume now we have a tree, although we are quite clear about its structure, we may not be sure about the location of the node in the dataset. For example, a node is named as 'no surfacing', how could we tell whether the feature 'no surfacing' is at the first column, or second in the dataset? This problem could be solved by recursion for each node in a tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, labels, subject):\n",
    "    firstkey = list(tree.keys())[0]\n",
    "    subdic = tree[firstkey]\n",
    "    feature = labels.index(firstkey)\n",
    "    for key in subdic.keys():\n",
    "        if subject[feature] == key:\n",
    "            if type(subdic[key]).__name__ == 'dict':\n",
    "                label = classify(subdic[key], labels, subject)\n",
    "            else:\n",
    "                label = subdic[key]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "tree = {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n",
    "print(classify(tree, ['no surfacing','flippers'], [1,0]))\n",
    "print(classify(tree, ['no surfacing','flippers'], [1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Lense Suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['young', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['young', 'myope', 'no', 'normal', 'soft'],\n",
       " ['young', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['young', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['young', 'hyper', 'no', 'reduced', 'no lenses']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lense_data = []\n",
    "with open('lenses.txt') as f:\n",
    "    content = f.readlines()\n",
    "    for line in content:\n",
    "        line = line.strip()\n",
    "        line = line.split('\\t')\n",
    "        lense_data.append(line)\n",
    "        \n",
    "lense_data[:5][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tearrate': {'reduced': 'no lenses',\n",
       "  'normal': {'astigmatic': {'yes': {'prescript': {'hyper': {'age': {'presbyopic': 'no lenses',\n",
       "        'young': 'hard',\n",
       "        'pre': 'no lenses'}},\n",
       "      'myope': 'hard'}},\n",
       "    'no': {'age': {'presbyopic': {'prescript': {'hyper': 'soft',\n",
       "        'myope': 'no lenses'}},\n",
       "      'young': 'soft',\n",
       "      'pre': 'soft'}}}}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lense_labels = ['age','prescript','astigmatic','tearrate']\n",
    "lense_tree = ID3(lense_data, lense_labels)\n",
    "lense_tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
